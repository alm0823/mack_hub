\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
\usepackage{hyperref}
\usepackage{amsmath} %for binomial pdf
\usepackage{parskip} % so that there's space bw paragraphs
\usepackage{float}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{STAT 532: Bayes} % Top left header
\chead{HW 2} % Top center header
\rhead{Andrea Mack} % Top right header
\lfoot{09/26/2016} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs
\setlength\parskip{0.5cm}
\restylefloat{table}

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}


%----------------------------------------------------------------------------------------%

\begin{document}
<<setup, include = FALSE>>=
require(xtable)

opts_chunk$set(echo = FALSE, warning = FALSE)
@

\begin{enumerate}
\item%1
<<prob1, include = FALSE>>=
unif_p <- c(seq(0.01,0.99, 0.01))

fn_rbinom <- function(x){
  #generate 30 random variables from a binomal distribution with probability x, n=30
  n <- 30
  rbinom_p <- rbinom(1,n,x)
  return(rbinom_p)
}
  #make an empty data frame
rbinom_p_out <- data.frame(matrix(NA,nrow = 99, ncol=10000))

#-------------------------------------------------#
#############for step 2 in prob1 ##################
  #apply fn_rbinom function to every element in unif_p, 10,000 times
for(i in 1:length(unif_p)){
  rbinom_p_out[i,] <- replicate(10000, sapply(unif_p[i], fn_rbinom))
  }
  #rbinom_p contains 10,000 realizations of a bniom(30,unif_p) distribution for each unif_p 
  #check dim(rbinom_p_out) == 99*10000
  #check any(is.na(rbinom_p_out)) -> good, no NA's
###################################################
#-------------------------------------------------#

  #create a ci for each proportion of successes based on rbinom_p/n
fn_lb <- function(x){
n <- 30
phat <- x/n
lb <- phat - 1.96*sqrt(phat*(1-phat)/n)
return(lb)
}

fn_ub <- function(x){
n <- 30
phat <- x/n
ub <- phat + 1.96*sqrt(phat*(1-phat)/n)
return(ub)
}

  #get lb and ub for a ci based on each realized rbinom_p_out
lb.test <- NULL 
lb.test <- data.frame(apply(rbinom_p_out, 2, fn_lb))
ub.test <- data.frame(apply(rbinom_p_out, 2, fn_ub))

#run with caution -- takes about 15 minutes!

#ind <- data.frame(matrix(NA, nrow = dim(rbinom_p_out)[1], ncol = dim(rbinom_p_out)[2]))
#for(i in 1:dim(rbinom_p_out)[1]){
  #for(j in 1:dim(rbinom_p_out)[2]){
  #ind[i,j] <- between(unif_p[i], lb.test[i,j], ub.test[i,j])
#}
#}

fn_prop <- function(x){
  ind_prop <- length(which(x == TRUE))/length(x)
  return(ind_prop)
}

r_seq <- c(1:dim(rbinom_p_out)[1])
ind_prop_out <- NULL
for(i in 1:dim(rbinom_p_out)[1]){
  ind_prop_out[i] <- fn_prop(ind[i,])
}

ind_prop_out_saved <- c(0.2638, 0.4491, 0.5945, 0.7033, 0.7797, 0.8389, 0.8839, 0.9130, 0.9419, 0.8132, 0.8501, 0.8796, 0.9071, 0.9290, 0.9433, 0.8661, 0.8949, 0.9176, 0.9244, 0.9443, 0.8853, 0.9030, 0.9261, 0.9398, 0.9433, 0.9114, 0.9243, 0.9277,0.9491, 0.9544, 0.9126, 0.9236, 0.9487, 0.9482, 0.9128, 0.9398, 0.9406, 0.9389, 0.9250, 0.9352, 0.9357, 0.9355, 0.9295, 0.9343, 0.9362, 0.9352, 0.9266, 0.9312, 0.9328, 0.9542, 0.9323, 0.9305, 0.9332, 0.9277, 0.9392, 0.9365, 0.9317, 0.9382, 0.9423, 0.9357, 0.9288, 0.9366, 0.9406, 0.9361, 0.9101, 0.9473, 0.9429, 0.9202, 0.9078, 0.9520,0.9451, 0.9237, 0.9202, 0.9076, 0.9434, 0.9326, 0.9261, 0.9002, 0.8925, 0.9482, 0.9273, 0.9181, 0.9000, 0.8667, 0.9442, 0.9270, 0.9043, 0.8810, 0.8534, 0.8089, 0.9397, 0.9076, 0.8844, 0.8474, 0.7825, 0.7003, 0.5962, 0.4570, 0.2585)
#-----------------------------------------------------------------------------#
@

<<moses.code, include = FALSE>>=
#Question 1
p<-seq(0.01,0.99,by=0.01)

n<-30
Bin<-rbinom(99,n,p)
Bin
install.packages("binom")
library('binom')
Interval<-binom.confint(Bin, n, conf.level = 0.95, methods = "asymptotic")
Interval
# This creates the  wald interval

replicate(10, rbinom(99,n,p))

check<-cbind( Interval[,5] <= p & Interval[,6] >= p )
# Checking to see if p falls in the interval





@

<<prob1.step3>>=

n_seq <- c(50:100)
#now make the above a function to run for each n_seq



@




\item%2

\begin{enumerate}
\item%2a
\item%2b
\item%2c
textttt

\end{enumerate}
\item%3
\begin{enumerate}
\item%3a


<<prob3a, results = 'asis', fig.pos='htb!'>>=
ya <- c(12,9,12,14,13,13,15,8,15,6)
yb <- c(11,11,10,9,9,8,7,10,6,8,8,9,7)

na <- length(ya)
nb <- length(yb)

#post_a
alpha_a <- 120
beta_a <- 10

post_alpha_a <- sum(ya) + alpha_a
post_beta_a <- 1 + (1/beta_a)

#post_b
alpha_b <- 12
beta_b <- 1

post_alpha_b <- sum(yb) + alpha_b
post_beta_b <- 1 + (1/beta_b)

#mean gamma is alpha*beta
#var of gamma is alpha*beta^2

#gamma distribution, scale = beta and shape = alpha

post_mean_a <- post_alpha_a*post_beta_a
post_var_a <- post_mean_a*post_beta_a

post_mean_b <- post_alpha_b*post_beta_b
post_var_b <- post_mean_b*post_beta_b

lb_a <- qgamma(0.025, shape = post_alpha_a, scale = post_beta_a )
ub_a <- qgamma(0.975, shape = post_alpha_a, scale = post_beta_a )


lb_b <- qgamma(0.025, shape = post_alpha_b, scale = post_beta_b )
ub_b <- qgamma(0.975, shape = post_alpha_b, scale = post_beta_b )

a <- c(post_alpha_a, post_beta_a, post_mean_a, post_var_a, lb_a, ub_a)
b <- c(post_alpha_b, post_beta_b, post_mean_b, post_var_b, lb_b, ub_b)

ab <- data.frame(rbind(a,b))
colnames(ab) <- c("Posterior Shape", "Posterior Scale", "Posterior Mean", "Posterior Variance", "Lower Bound", "Upper Bound")

rownames(ab) <- c("A", "B")

print(xtable(ab), table.placement = 'htb!')
@

\item%3b

<<prob3b, fig.pos = 'htb!', fig.height=5, fig.width=5>>=
#3b
no <- c(1:50)

fn <- function(x){
  a1 <- sum(yb) + (12*x)
  b1 <- 1 + (1/x)
  meanb1 <- a1*b1
  return(meanb1)
}

eb <- c(sapply(no, fn))


plot(eb~no)
abline(h = post_mean_a, add = TRUE)
abline(h = eb[10], add = TRUE, col = "purple")
abline(h = ab[11], add = TRUE, col = "purple")
@

<<prob3bx, results = 'asis'>>=

r <- c(post_mean_a -10, post_mean_a +10)
#which(eb < r[2] & eb > r[1])
#eb[10]
#eb[11]

cat("The post mean of", "$\\theat_{A}$", "is between", eb[10], "and", eb[11], "Which corresponds to when no is 10 and 11. For the posterior expectation of", "$\\theta_{B}$", "to be close to that of", "$\\theta_{A}$", "no would need to be close to 10 or 11, which would make the prior distribution of",
"$\\theta_{B}$", "to be close to a GAM(120,10) or a GAM(130,10) distribution.")
@
\end{enumerate}
\item%4
\end{enumerate}

\end{document}